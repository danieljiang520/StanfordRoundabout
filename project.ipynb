{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa170e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports - ignore\n",
    "# !pip install gymnasium stable_baselines3[extra] opencv-python highway_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a162b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from stable_baselines3 import DQN\n",
    "import numpy as np\n",
    "import highway_env  # noqa: F401\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6227b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/williamzhang/Documents/StanfordRoundabout/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ce325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safety_margin(env, agent_id):\n",
    "    \"\"\"\n",
    "    Calculate the safety margin of the agent in the environment.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2a8af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "TRAIN = False\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"roundabout-v0\", render_mode=\"rgb_array\")\n",
    "obs, info = env.reset()\n",
    "\n",
    "# Create the model\n",
    "model = DQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=dict(net_arch=[256, 256]),\n",
    "    learning_rate=5e-4,\n",
    "    buffer_size=15000,\n",
    "    learning_starts=200,\n",
    "    batch_size=32,\n",
    "    gamma=0.8,\n",
    "    train_freq=1,\n",
    "    gradient_steps=1,\n",
    "    target_update_interval=50,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"roundabout_dqn/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f459cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "if TRAIN:\n",
    "    model.learn(total_timesteps=int(2e4))\n",
    "    model.save(\"roundabout_dqn/model\")\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64680f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# Run the trained model and record video\n",
    "model = DQN.load(\"roundabout_dqn/model\", env=env, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5be3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_environments = 30       # unique environment configurations (seeds)\n",
    "num_trajectories = 5        # trajectories per environment\n",
    "\n",
    "# Store metrics per environment: env_metrics[env_idx] = {metric: [traj_values]}\n",
    "env_metrics = []\n",
    "\n",
    "for env_idx in range(num_environments):\n",
    "    seed = env_idx * 100  # deterministic, reproducible seeds\n",
    "\n",
    "    traj_metrics = {\n",
    "        \"success\": [],\n",
    "        \"min_distance\": [],\n",
    "        \"avg_speed_ratio\": [],\n",
    "        \"jerk_score\": [],\n",
    "        \"hard_brakes\": [],\n",
    "        \"brake_severity\": [],\n",
    "        \"lane_changes\": [],\n",
    "        \"on_road_frac\": [],\n",
    "        \"cumulative_reward\": [],\n",
    "    }\n",
    "\n",
    "    for traj_idx in range(num_trajectories):\n",
    "        # Reset with the SAME seed to get the same initial environment layout,\n",
    "        # but use deterministic=False so the DQN's epsilon-greedy exploration\n",
    "        # produces different trajectories in the same scenario.\n",
    "        obs, info = env.reset(seed=seed)\n",
    "        done = truncated = False\n",
    "\n",
    "        velocities = []\n",
    "        min_dist = float(\"inf\")\n",
    "        lane_changes = 0\n",
    "        on_road_steps = 0\n",
    "        total_steps = 0\n",
    "        cumulative_reward = 0.0\n",
    "        prev_action = None\n",
    "\n",
    "        while not (done or truncated):\n",
    "            action, _ = model.predict(obs, deterministic=False)\n",
    "\n",
    "            if prev_action is not None and action != prev_action and action in [0, 2]:\n",
    "                lane_changes += 1\n",
    "            prev_action = action\n",
    "\n",
    "            obs, reward, done, truncated, info = env.step(action)\n",
    "            cumulative_reward += reward\n",
    "            total_steps += 1\n",
    "\n",
    "            # Use raw vehicle state from the environment (avoids normalization issues)\n",
    "            ego = env.unwrapped.vehicle\n",
    "            velocities.append(np.sqrt(ego.velocity[0]**2 + ego.velocity[1]**2))\n",
    "\n",
    "            for vehicle in env.unwrapped.road.vehicles:\n",
    "                if vehicle is not ego:\n",
    "                    dist = np.linalg.norm(ego.position - vehicle.position)\n",
    "                    min_dist = min(min_dist, dist)\n",
    "                    \n",
    "\n",
    "            if env.unwrapped.vehicle.on_road:\n",
    "                on_road_steps += 1\n",
    "\n",
    "        velocities = np.array(velocities)\n",
    "        dt = 1.0 / env.unwrapped.config[\"policy_frequency\"]  # time between decisions\n",
    "        accel = np.diff(velocities) / dt  # m/s²\n",
    "        jerk = np.diff(accel) / dt        # m/s³\n",
    "\n",
    "        # Hard braking: count of steps where deceleration exceeds 4 m/s²\n",
    "        hard_brake_threshold = 4.0  # m/s²\n",
    "        hard_brakes = int(np.sum(accel < -hard_brake_threshold))\n",
    "\n",
    "        # Brake severity: quadratic penalty for deceleration beyond threshold\n",
    "        # Captures *how hard* the brakes were, not just how often\n",
    "        excess_decel = np.clip(-accel - hard_brake_threshold, 0, None)\n",
    "        brake_severity = float(np.sum(excess_decel**2))\n",
    "\n",
    "        traj_metrics[\"success\"].append(0.0 if env.unwrapped.vehicle.crashed else 1.0)\n",
    "        traj_metrics[\"min_distance\"].append(min_dist if min_dist != float(\"inf\") else 0.0)\n",
    "        traj_metrics[\"avg_speed_ratio\"].append(np.mean(velocities) / 16.0)\n",
    "        traj_metrics[\"jerk_score\"].append(np.mean(jerk**2) if len(jerk) > 0 else 0.0)\n",
    "        traj_metrics[\"hard_brakes\"].append(hard_brakes)\n",
    "        traj_metrics[\"brake_severity\"].append(brake_severity)\n",
    "        traj_metrics[\"lane_changes\"].append(lane_changes)\n",
    "        traj_metrics[\"on_road_frac\"].append(on_road_steps / max(total_steps, 1))\n",
    "        traj_metrics[\"cumulative_reward\"].append(cumulative_reward)\n",
    "\n",
    "    env_metrics.append(traj_metrics)\n",
    "\n",
    "# ── Per-environment summary ──\n",
    "print(f\"=== Robustness Metrics ({num_environments} environments × {num_trajectories} trajectories) ===\\n\")\n",
    "print(f\"{'Env':>4}  {'Seed':>5}  {'Success':>8}  {'MinDist':>8}  {'SpeedR':>7}  {'Jerk':>9}  {'HBrake':>7}  {'BrkSev':>8}  {'LaneCh':>7}  {'OnRoad':>7}  {'Reward':>9}\")\n",
    "print(\"-\" * 102)\n",
    "\n",
    "all_success, all_min_dist, all_speed, all_jerk, all_hb, all_bs, all_lc, all_road, all_reward = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "for env_idx, m in enumerate(env_metrics):\n",
    "    seed = env_idx * 100\n",
    "    sr = np.mean(m[\"success\"])\n",
    "    md = np.mean(m[\"min_distance\"])\n",
    "    sp = np.mean(m[\"avg_speed_ratio\"])\n",
    "    jk = np.mean(m[\"jerk_score\"])\n",
    "    hb = np.mean(m[\"hard_brakes\"])\n",
    "    bs = np.mean(m[\"brake_severity\"])\n",
    "    lc = np.mean(m[\"lane_changes\"])\n",
    "    rd = np.mean(m[\"on_road_frac\"])\n",
    "    rw = np.mean(m[\"cumulative_reward\"])\n",
    "    print(f\"{env_idx:>4}  {seed:>5}  {sr:>7.0%}  {md:>8.3f}  {sp:>7.3f}  {jk:>9.5f}  {hb:>7.1f}  {bs:>8.2f}  {lc:>7.1f}  {rd:>6.0%}  {rw:>9.3f}\")\n",
    "\n",
    "    all_success.extend(m[\"success\"])\n",
    "    all_min_dist.extend(m[\"min_distance\"])\n",
    "    all_speed.extend(m[\"avg_speed_ratio\"])\n",
    "    all_jerk.extend(m[\"jerk_score\"])\n",
    "    all_hb.extend(m[\"hard_brakes\"])\n",
    "    all_bs.extend(m[\"brake_severity\"])\n",
    "    all_lc.extend(m[\"lane_changes\"])\n",
    "    all_road.extend(m[\"on_road_frac\"])\n",
    "    all_reward.extend(m[\"cumulative_reward\"])\n",
    "\n",
    "# ── Aggregate summary ──\n",
    "print(\"\\n=== Aggregate (all trajectories) ===\")\n",
    "print(f\"  Success Rate:          {np.mean(all_success):.2%}\")\n",
    "print(f\"  Min Safety Distance:   {np.mean(all_min_dist):.3f} m  (std={np.std(all_min_dist):.3f})\")\n",
    "print(f\"  Avg Speed Ratio:       {np.mean(all_speed):.3f}  (std={np.std(all_speed):.3f})\")\n",
    "print(f\"  Jerk (lower=smoother): {np.mean(all_jerk):.5f}\")\n",
    "print(f\"  Hard Brakes/ep:        {np.mean(all_hb):.1f}  (count, decel > 4 m/s²)\")\n",
    "print(f\"  Brake Severity/ep:    {np.mean(all_bs):.2f}  (quadratic penalty beyond threshold)\")\n",
    "print(f\"  Lane Changes/ep:       {np.mean(all_lc):.1f}\")\n",
    "print(f\"  On-Road Fraction:      {np.mean(all_road):.2%}\")\n",
    "print(f\"  Cumulative Reward:     {np.mean(all_reward):.3f}  (std={np.std(all_reward):.3f})\")\n",
    "\n",
    "# ── Within-environment consistency (how stable is the policy in the same scenario?) ──\n",
    "reward_stds = [np.std(m[\"cumulative_reward\"]) for m in env_metrics]\n",
    "success_stds = [np.std(m[\"success\"]) for m in env_metrics]\n",
    "print(f\"\\n=== Within-Environment Consistency ===\")\n",
    "print(f\"  Avg reward std per env:  {np.mean(reward_stds):.3f}  (lower = more consistent)\")\n",
    "print(f\"  Avg success std per env: {np.mean(success_stds):.3f}\")\n",
    "\n",
    "# ── Composite robustness score ──\n",
    "w = {\"safety\": 0.4, \"stability\": 0.2, \"efficiency\": 0.2, \"road\": 0.2}\n",
    "norm_safety = np.clip(np.mean(all_min_dist) / 20.0, 0, 1)\n",
    "norm_stability = 1.0 - np.clip(np.mean(all_jerk) / 0.1, 0, 1)\n",
    "norm_efficiency = np.clip(np.mean(all_speed), 0, 1)\n",
    "norm_road = np.mean(all_road)\n",
    "\n",
    "robustness = (\n",
    "    w[\"safety\"] * norm_safety\n",
    "    + w[\"stability\"] * norm_stability\n",
    "    + w[\"efficiency\"] * norm_efficiency\n",
    "    + w[\"road\"] * norm_road\n",
    ")\n",
    "print(f\"\\n  Composite Robustness Score: {robustness:.4f}  (range [0, 1])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477535cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/CS238V-Cars\n"
     ]
    }
   ],
   "source": [
    "# # Change working directory\n",
    "# import os\n",
    "# os.chdir('/content/drive/MyDrive/CS238V-Cars/')  # put your folder path here\n",
    "\n",
    "# # Check current working directory\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e03911d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dkoffical/envs/myenv312/lib/python3.12/site-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /Users/dkoffical/Documents/GitHub/StanfordRoundabout/roundabout_dqn/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run the trained model and record video\n",
    "model = DQN.load(\"roundabout_dqn/model\", env=env, device=\"cpu\")\n",
    "# model.set_env(env)\n",
    "env = RecordVideo(\n",
    "    env, video_folder=\"roundabout_dqn/videos\", episode_trigger=lambda e: True\n",
    ")\n",
    "env.unwrapped.config[\"simulation_frequency\"] = 15  # Higher FPS for rendering\n",
    "env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "for videos in range(10):\n",
    "    done = truncated = False\n",
    "    obs, info = env.reset()\n",
    "    while not (done or truncated):\n",
    "        # Predict\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        # Get reward\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        # Render\n",
    "        env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a994c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > colab_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed8e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 2.0.2\n",
      "gymnasium: 1.2.3\n",
      "stable_baselines3: 2.7.1\n",
      "opencv-python: 4.13.0\n",
      "highway_env: 1.10.2\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "# # import numpy\n",
    "# # import gymnasium\n",
    "# # import stable_baselines3\n",
    "# # import cv2\n",
    "# # import highway_env\n",
    "# import torch\n",
    "# import torchvision\n",
    "# import torchaudio\n",
    "\n",
    "\n",
    "# # print(\"numpy:\", numpy.__version__)\n",
    "# # print(\"gymnasium:\", gymnasium.__version__)\n",
    "# # print(\"stable_baselines3:\", stable_baselines3.__version__)\n",
    "# # print(\"opencv-python:\", cv2.__version__)\n",
    "# # print(\"highway_env:\", highway_env.__version__)\n",
    "\n",
    "# print(\"torch:\", torch.__version__)\n",
    "# print(\"torchvision:\", torchvision.__version__)\n",
    "# print(\"torchaudio:\", torchaudio.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
